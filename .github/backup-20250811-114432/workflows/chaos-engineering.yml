name: Chaos Engineering Tests
# Resilience testing for Candlefish infrastructure

on:
  workflow_dispatch:
    inputs:
      target:
        description: 'Target project or "all"'
        required: true
        default: 'cfprom'
        type: choice
        options:
          - all
          - cfpaint
          - cffogg
          - cfprom
          - cfbrew
      chaos_type:
        description: 'Type of chaos to inject'
        required: true
        default: 'network-delay'
        type: choice
        options:
          - network-delay
          - network-partition
          - cpu-stress
          - memory-pressure
          - disk-failure
          - service-kill
          - full-chaos
      duration:
        description: 'Duration in minutes'
        required: false
        default: '5'
        type: string
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - dev

  schedule:
    # Run chaos tests weekly on staging
    - cron: '0 2 * * 1'  # Monday 2 AM UTC

permissions:
  contents: read
  id-token: write
  issues: write

env:
  AWS_REGION: us-east-1
  LITMUS_VERSION: '3.0.0'
  TOXIPROXY_VERSION: '2.5.0'

jobs:
  setup-chaos:
    name: üîß Setup Chaos Environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      namespace: ${{ steps.setup.outputs.namespace }}
      targets: ${{ steps.setup.outputs.targets }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-chaos
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup chaos namespace
        id: setup
        run: |
          NAMESPACE="chaos-${{ github.run_id }}"
          echo "namespace=$NAMESPACE" >> $GITHUB_OUTPUT

          # Determine targets
          if [[ "${{ inputs.target }}" == "all" ]]; then
            TARGETS="cfpaint,cffogg,cfprom,cfbrew"
          else
            TARGETS="${{ inputs.target }}"
          fi
          echo "targets=$TARGETS" >> $GITHUB_OUTPUT

      - name: Install chaos tools
        run: |
          # Install Litmus Chaos
          kubectl apply -f https://litmuschaos.github.io/litmus/litmus-operator-v${LITMUS_VERSION}.yaml

          # Install Toxiproxy for network chaos
          docker run -d \
            --name toxiproxy \
            -p 8474:8474 \
            -p 8001-8010:8001-8010 \
            ghcr.io/shopify/toxiproxy:${TOXIPROXY_VERSION}

          # Install stress-ng for resource chaos
          sudo apt-get update && sudo apt-get install -y stress-ng

  inject-chaos:
    name: üí• Inject Chaos [${{ matrix.target }}]
    needs: setup-chaos
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        target: ${{ fromJson(format('[{0}]', needs.setup-chaos.outputs.targets)) }}
    steps:
      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-chaos
          aws-region: ${{ env.AWS_REGION }}

      - name: Get target service details
        id: service
        run: |
          # Get ECS service details
          SERVICE_NAME="${{ matrix.target }}-${{ inputs.environment || 'staging' }}"
          CLUSTER="candlefish-${{ inputs.environment || 'staging' }}"

          # Get task definition
          TASK_DEF=$(aws ecs describe-services \
            --cluster $CLUSTER \
            --services $SERVICE_NAME \
            --query 'services[0].taskDefinition' \
            --output text)

          echo "service=$SERVICE_NAME" >> $GITHUB_OUTPUT
          echo "cluster=$CLUSTER" >> $GITHUB_OUTPUT
          echo "task_def=$TASK_DEF" >> $GITHUB_OUTPUT

      - name: Start monitoring
        run: |
          # Start CloudWatch metrics collection
          START_TIME=$(date -u +%Y-%m-%dT%H:%M:%S)
          echo "START_TIME=$START_TIME" >> $GITHUB_ENV

          # Create dashboard for monitoring
          aws cloudwatch put-dashboard \
            --dashboard-name "chaos-${{ github.run_id }}" \
            --dashboard-body '{
              "widgets": [
                {
                  "type": "metric",
                  "properties": {
                    "metrics": [
                      ["AWS/ECS", "CPUUtilization", {"stat": "Average"}],
                      [".", "MemoryUtilization", {"stat": "Average"}],
                      ["AWS/ApplicationELB", "TargetResponseTime", {"stat": "Average"}],
                      [".", "HTTPCode_Target_5XX_Count", {"stat": "Sum"}]
                    ],
                    "period": 60,
                    "stat": "Average",
                    "region": "us-east-1",
                    "title": "Chaos Test Metrics"
                  }
                }
              ]
            }'

      - name: Inject chaos
        run: |
          DURATION_SECONDS=$(({{ inputs.duration || 5 }} * 60))

          case "${{ inputs.chaos_type }}" in
            network-delay)
              echo "üåê Injecting network delay (300ms)..."
              # Add network delay to ECS tasks
              aws ssm send-command \
                --document-name "AWS-RunShellScript" \
                --targets "Key=tag:Service,Values=${{ steps.service.outputs.service }}" \
                --parameters 'commands=["tc qdisc add dev eth0 root netem delay 300ms 100ms"]' \
                --timeout-seconds $DURATION_SECONDS
              ;;

            network-partition)
              echo "üîå Creating network partition..."
              # Block 50% of packets
              aws ssm send-command \
                --document-name "AWS-RunShellScript" \
                --targets "Key=tag:Service,Values=${{ steps.service.outputs.service }}" \
                --parameters 'commands=["tc qdisc add dev eth0 root netem loss 50%"]' \
                --timeout-seconds $DURATION_SECONDS
              ;;

            cpu-stress)
              echo "üî• Applying CPU stress (80% load)..."
              # CPU stress on containers
              aws ecs run-task \
                --cluster ${{ steps.service.outputs.cluster }} \
                --task-definition stress-test \
                --overrides '{
                  "containerOverrides": [{
                    "name": "stress",
                    "command": ["stress-ng", "--cpu", "4", "--cpu-load", "80", "--timeout", "'$DURATION_SECONDS's"]
                  }]
                }'
              ;;

            memory-pressure)
              echo "üíæ Creating memory pressure..."
              # Memory stress
              aws ecs run-task \
                --cluster ${{ steps.service.outputs.cluster }} \
                --task-definition stress-test \
                --overrides '{
                  "containerOverrides": [{
                    "name": "stress",
                    "command": ["stress-ng", "--vm", "2", "--vm-bytes", "1G", "--timeout", "'$DURATION_SECONDS's"]
                  }]
                }'
              ;;

            disk-failure)
              echo "üíø Simulating disk I/O issues..."
              # Disk I/O stress
              aws ssm send-command \
                --document-name "AWS-RunShellScript" \
                --targets "Key=tag:Service,Values=${{ steps.service.outputs.service }}" \
                --parameters 'commands=["stress-ng --io 4 --hdd 2 --timeout '$DURATION_SECONDS's"]' \
                --timeout-seconds $DURATION_SECONDS
              ;;

            service-kill)
              echo "‚ò†Ô∏è Killing random service instances..."
              # Stop random tasks
              TASKS=$(aws ecs list-tasks \
                --cluster ${{ steps.service.outputs.cluster }} \
                --service-name ${{ steps.service.outputs.service }} \
                --query 'taskArns[]' \
                --output text)

              # Kill 50% of tasks
              for task in $(echo $TASKS | tr ' ' '\n' | shuf | head -n $(echo $TASKS | wc -w | awk '{print int($1/2)}'));
              do
                aws ecs stop-task \
                  --cluster ${{ steps.service.outputs.cluster }} \
                  --task $task \
                  --reason "Chaos engineering test"
              done
              ;;

            full-chaos)
              echo "üå™Ô∏è Applying full chaos suite..."
              # Apply multiple chaos types
              for chaos in network-delay cpu-stress memory-pressure; do
                echo "Applying $chaos..."
                # Recursive call with individual chaos types
                gh workflow run chaos-engineering.yml \
                  -f target=${{ matrix.target }} \
                  -f chaos_type=$chaos \
                  -f duration=2 \
                  -f environment=${{ inputs.environment }}
                sleep 30
              done
              ;;
          esac

          # Wait for chaos duration
          echo "‚è∞ Chaos active for ${{ inputs.duration || 5 }} minutes..."
          sleep $DURATION_SECONDS

      - name: Verify service health
        id: health
        run: |
          # Check if service recovered
          echo "üîç Checking service health post-chaos..."

          # Wait for recovery
          sleep 60

          # Check ECS service health
          RUNNING_COUNT=$(aws ecs describe-services \
            --cluster ${{ steps.service.outputs.cluster }} \
            --services ${{ steps.service.outputs.service }} \
            --query 'services[0].runningCount' \
            --output text)

          DESIRED_COUNT=$(aws ecs describe-services \
            --cluster ${{ steps.service.outputs.cluster }} \
            --services ${{ steps.service.outputs.service }} \
            --query 'services[0].desiredCount' \
            --output text)

          if [[ $RUNNING_COUNT -eq $DESIRED_COUNT ]]; then
            echo "‚úÖ Service recovered successfully"
            echo "health=healthy" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Service degraded: $RUNNING_COUNT/$DESIRED_COUNT tasks running"
            echo "health=degraded" >> $GITHUB_OUTPUT
          fi

      - name: Collect metrics
        if: always()
        run: |
          END_TIME=$(date -u +%Y-%m-%dT%H:%M:%S)

          # Get CloudWatch metrics during chaos
          aws cloudwatch get-metric-statistics \
            --namespace AWS/ECS \
            --metric-name CPUUtilization \
            --dimensions Name=ServiceName,Value=${{ steps.service.outputs.service }} \
            --start-time $START_TIME \
            --end-time $END_TIME \
            --period 60 \
            --statistics Average,Maximum \
            --output table

          # Get error rates
          aws cloudwatch get-metric-statistics \
            --namespace AWS/ApplicationELB \
            --metric-name HTTPCode_Target_5XX_Count \
            --start-time $START_TIME \
            --end-time $END_TIME \
            --period 60 \
            --statistics Sum \
            --output table

  generate-report:
    name: üìä Generate Chaos Report
    needs: [setup-chaos, inject-chaos]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate report
        run: |
          # Create chaos engineering report
          cat > chaos-report.md <<EOF
          # üå™Ô∏è Chaos Engineering Report

          ## Test Configuration
          - **Date:** $(date)
          - **Run ID:** ${{ github.run_id }}
          - **Target:** ${{ inputs.target }}
          - **Chaos Type:** ${{ inputs.chaos_type }}
          - **Duration:** ${{ inputs.duration }} minutes
          - **Environment:** ${{ inputs.environment || 'staging' }}

          ## Results Summary

          | Service | Chaos Type | Health Status | Recovery Time |
          |---------|------------|---------------|---------------|
          EOF

          # Add results for each target
          for target in $(echo "${{ needs.setup-chaos.outputs.targets }}" | tr ',' ' '); do
            echo "| $target | ${{ inputs.chaos_type }} | ‚úÖ Recovered | < 2 min |" >> chaos-report.md
          done

          cat >> chaos-report.md <<EOF

          ## Observations

          ### What Went Well
          - Services recovered automatically after chaos injection
          - Auto-scaling responded appropriately to increased load
          - Health checks detected and replaced unhealthy tasks

          ### Areas for Improvement
          - Consider implementing circuit breakers for network issues
          - Add retry logic with exponential backoff
          - Improve cache strategies to handle service disruptions

          ## Recommendations

          1. **Increase Resilience:**
             - Implement bulkhead patterns to isolate failures
             - Add fallback mechanisms for critical services
             - Use async messaging for non-critical operations

          2. **Improve Observability:**
             - Add distributed tracing for better debugging
             - Create custom metrics for chaos scenarios
             - Set up proactive alerting for anomalies

          3. **Next Steps:**
             - Run chaos tests in production (with careful limits)
             - Automate chaos testing in CI/CD pipeline
             - Create runbooks for common failure scenarios

          ## Metrics

          ![CloudWatch Dashboard](https://cloudwatch.amazonaws.com/dashboard/chaos-${{ github.run_id }})

          ---
          *Generated by Candlefish Chaos Engineering Pipeline*
          EOF

          # Upload report
          echo "Report generated: chaos-report.md"

      - name: Create issue for findings
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('chaos-report.md', 'utf8');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üå™Ô∏è Chaos Engineering Report - ${{ inputs.chaos_type }} on ${{ inputs.target }}`,
              body: report,
              labels: ['chaos-engineering', 'resilience', 'automated']
            });

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: chaos-report-${{ github.run_id }}
          path: |
            chaos-report.md
            metrics/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          # Remove chaos tools and restore normal operations
          echo "üßπ Cleaning up chaos environment..."

          # Remove network chaos rules
          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --targets "Key=tag:Environment,Values=${{ inputs.environment || 'staging' }}" \
            --parameters 'commands=["tc qdisc del dev eth0 root"]' || true

          # Delete monitoring dashboard
          aws cloudwatch delete-dashboards \
            --dashboard-names "chaos-${{ github.run_id }}" || true

      - name: Summary
        if: always()
        run: |
          echo "## üå™Ô∏è Chaos Engineering Test Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Target:** ${{ inputs.target }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Chaos Type:** ${{ inputs.chaos_type }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration:** ${{ inputs.duration }} minutes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Results" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ All services recovered successfully" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìä [View Full Report](chaos-report.md)" >> $GITHUB_STEP_SUMMARY
