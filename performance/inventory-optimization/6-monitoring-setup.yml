# Performance Monitoring Setup with Prometheus and Grafana
# Complete monitoring stack for inventory management system

version: '3.8'

services:
  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: inventory-prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert-rules.yml:/etc/prometheus/alert-rules.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - monitoring
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: inventory-grafana
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana-provisioning:/etc/grafana/provisioning
      - ./dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=redis-datasource,cloudflare-app,grafana-piechart-panel
      - GF_SERVER_ROOT_URL=https://monitoring.candlefish.ai
      - GF_ANALYTICS_REPORTING_ENABLED=false
    ports:
      - "3000:3000"
    networks:
      - monitoring
    restart: unless-stopped
    depends_on:
      - prometheus

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: inventory-node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    networks:
      - monitoring
    restart: unless-stopped

  # Redis Exporter for cache metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: inventory-redis-exporter
    environment:
      - REDIS_ADDR=redis://redis.candlefish.ai:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    ports:
      - "9121:9121"
    networks:
      - monitoring
    restart: unless-stopped

  # Postgres Exporter for database metrics
  postgres-exporter:
    image: wrouesnel/postgres_exporter:latest
    container_name: inventory-postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://user:password@postgres.candlefish.ai:5432/inventory_db?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - monitoring
    restart: unless-stopped

  # Alertmanager for alert handling
  alertmanager:
    image: prom/alertmanager:latest
    container_name: inventory-alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    networks:
      - monitoring
    restart: unless-stopped

  # Loki for log aggregation
  loki:
    image: grafana/loki:latest
    container_name: inventory-loki
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yaml
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring
    restart: unless-stopped

  # Promtail for log collection
  promtail:
    image: grafana/promtail:latest
    container_name: inventory-promtail
    volumes:
      - /var/log:/var/log:ro
      - ./promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
    networks:
      - monitoring
    restart: unless-stopped

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: inventory-jaeger
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - monitoring
    restart: unless-stopped

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus-data:
  grafana-data:
  alertmanager-data:
  loki-data:

---
# prometheus.yml - Prometheus configuration
# Place in ./prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: 'candlefish-inventory'
    environment: 'production'

# Alert rules
rule_files:
  - '/etc/prometheus/alert-rules.yml'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# Scrape configurations
scrape_configs:
  # Prometheus self-monitoring
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node metrics
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
        labels:
          instance: 'inventory-server'

  # Redis metrics
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
        labels:
          instance: 'redis-cache'

  # PostgreSQL metrics
  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres-exporter:9187']
        labels:
          instance: 'postgres-db'

  # Application metrics (Kong Gateway)
  - job_name: 'kong'
    static_configs:
      - targets: ['kong.candlefish.ai:8001']
        labels:
          service: 'api-gateway'

  # Application metrics (GraphQL)
  - job_name: 'graphql'
    metrics_path: '/metrics'
    static_configs:
      - targets: ['api.candlefish.ai:4000']
        labels:
          service: 'graphql-api'

  # Application metrics (Inventory API)
  - job_name: 'inventory-api'
    metrics_path: '/metrics'
    static_configs:
      - targets: ['api.candlefish.ai:8080']
        labels:
          service: 'inventory-api'

  # Kubernetes metrics (if using k8s)
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

---
# alert-rules.yml - Alert rules
# Place in ./alert-rules.yml

groups:
  - name: inventory_alerts
    interval: 30s
    rules:
      # API Response Time Alert
      - alert: HighAPIResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          service: inventory-api
        annotations:
          summary: "High API response time (instance {{ $labels.instance }})"
          description: "95th percentile response time is {{ $value }}s (threshold: 100ms)"

      # Error Rate Alert
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
          service: inventory-api
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 1%)"

      # Cache Hit Rate Alert
      - alert: LowCacheHitRate
        expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) < 0.7
        for: 10m
        labels:
          severity: warning
          service: redis-cache
        annotations:
          summary: "Low Redis cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }} (threshold: 70%)"

      # Database Connection Pool Alert
      - alert: DatabaseConnectionPoolExhausted
        expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
        for: 5m
        labels:
          severity: critical
          service: postgresql
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "{{ $value | humanizePercentage }} of connections in use"

      # Memory Usage Alert
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      # Disk Space Alert
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Only {{ $value | humanizePercentage }} disk space remaining"

      # GraphQL Query Complexity Alert
      - alert: HighGraphQLComplexity
        expr: histogram_quantile(0.95, rate(graphql_query_complexity_bucket[5m])) > 1000
        for: 5m
        labels:
          severity: warning
          service: graphql
        annotations:
          summary: "High GraphQL query complexity"
          description: "95th percentile query complexity is {{ $value }}"

---
# grafana-dashboard.json - Main Performance Dashboard
# Place in ./dashboards/inventory-performance.json

{
  "dashboard": {
    "title": "Inventory Management Performance",
    "panels": [
      {
        "title": "API Response Time (p95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 }
      },
      {
        "title": "Requests Per Second",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 }
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 }
      },
      {
        "title": "Cache Hit Rate",
        "targets": [
          {
            "expr": "redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total)"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 }
      },
      {
        "title": "Database Query Time",
        "targets": [
          {
            "expr": "rate(pg_stat_statements_mean_exec_time[5m])"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 0, "y": 16 }
      },
      {
        "title": "Active Database Connections",
        "targets": [
          {
            "expr": "pg_stat_database_numbackends"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 12, "y": 16 }
      },
      {
        "title": "GraphQL Query Complexity",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(graphql_query_complexity_bucket[5m]))"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 0, "y": 24 }
      },
      {
        "title": "Memory Usage",
        "targets": [
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100"
          }
        ],
        "gridPos": { "h": 8, "w": 12, "x": 12, "y": 24 }
      }
    ],
    "refresh": "10s",
    "time": {
      "from": "now-1h",
      "to": "now"
    }
  }
}

---
# Custom metrics exporter for application
# Place in ./metrics-exporter.ts

import { Registry, Counter, Histogram, Gauge } from 'prom-client';

const register = new Registry();

// API metrics
export const httpRequestDuration = new Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status'],
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
  registers: [register],
});

export const httpRequestTotal = new Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status'],
  registers: [register],
});

// Cache metrics
export const cacheHits = new Counter({
  name: 'cache_hits_total',
  help: 'Total number of cache hits',
  labelNames: ['cache_type'],
  registers: [register],
});

export const cacheMisses = new Counter({
  name: 'cache_misses_total',
  help: 'Total number of cache misses',
  labelNames: ['cache_type'],
  registers: [register],
});

// GraphQL metrics
export const graphqlQueryComplexity = new Histogram({
  name: 'graphql_query_complexity',
  help: 'GraphQL query complexity score',
  labelNames: ['operation_name'],
  buckets: [10, 50, 100, 500, 1000, 5000],
  registers: [register],
});

export const graphqlQueryDuration = new Histogram({
  name: 'graphql_query_duration_seconds',
  help: 'GraphQL query execution time',
  labelNames: ['operation_name'],
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
  registers: [register],
});

// Database metrics
export const dbQueryDuration = new Histogram({
  name: 'db_query_duration_seconds',
  help: 'Database query execution time',
  labelNames: ['query_type'],
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],
  registers: [register],
});

export const dbConnectionPool = new Gauge({
  name: 'db_connection_pool_size',
  help: 'Current database connection pool size',
  labelNames: ['state'],
  registers: [register],
});

export { register };
