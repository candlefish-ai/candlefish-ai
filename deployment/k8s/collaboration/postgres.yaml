apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: collaboration
  labels:
    app.kubernetes.io/name: candlefish-collaboration
    app.kubernetes.io/component: database
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: gp3-csi
  resources:
    requests:
      storage: 100Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: collaboration
  labels:
    app.kubernetes.io/name: candlefish-collaboration
    app.kubernetes.io/component: database
    app.kubernetes.io/version: "15"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: postgres
      component: database
  template:
    metadata:
      labels:
        app: postgres
        component: database
        app.kubernetes.io/name: candlefish-collaboration
        app.kubernetes.io/component: database
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
    spec:
      securityContext:
        fsGroup: 999
        runAsUser: 999
        runAsGroup: 999
      containers:
      - name: postgres
        image: postgres:15-alpine
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: "collaboration_db"
        - name: POSTGRES_USER
          value: "collaboration_user"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: collaboration-secrets
              key: DB_PASSWORD
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
        - name: postgres-initdb
          mountPath: /docker-entrypoint-initdb.d
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -h
            - localhost
            - -U
            - collaboration_user
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -h
            - localhost
            - -U
            - collaboration_user
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"

      # PostgreSQL Exporter for Monitoring
      - name: postgres-exporter
        image: prometheuscommunity/postgres-exporter:v0.15.0
        ports:
        - containerPort: 9187
          name: metrics
        env:
        - name: DATA_SOURCE_NAME
          valueFrom:
            secretKeyRef:
              name: collaboration-secrets
              key: DATABASE_URL
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"

      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc
      - name: postgres-config
        configMap:
          name: postgres-config
      - name: postgres-initdb
        configMap:
          name: postgres-initdb

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: collaboration
  labels:
    app.kubernetes.io/name: candlefish-collaboration
    app.kubernetes.io/component: database
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
    name: postgres
  - port: 9187
    targetPort: 9187
    name: metrics
  selector:
    app: postgres
    component: database

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: collaboration
  labels:
    app.kubernetes.io/name: candlefish-collaboration
    app.kubernetes.io/component: database-config
data:
  postgresql.conf: |
    # PostgreSQL Configuration for Collaboration System

    # Connection Settings
    listen_addresses = '*'
    port = 5432
    max_connections = 200

    # Memory Settings
    shared_buffers = 256MB
    effective_cache_size = 1GB
    work_mem = 4MB
    maintenance_work_mem = 64MB

    # Write Ahead Logging
    wal_level = replica
    max_wal_size = 1GB
    min_wal_size = 80MB
    checkpoint_completion_target = 0.9

    # Query Planner
    random_page_cost = 1.1
    effective_io_concurrency = 200

    # Logging
    log_statement = 'mod'
    log_min_duration_statement = 1000
    log_checkpoints = on
    log_connections = on
    log_disconnections = on
    log_lock_waits = on

    # Performance
    default_statistics_target = 100

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-initdb
  namespace: collaboration
  labels:
    app.kubernetes.io/name: candlefish-collaboration
    app.kubernetes.io/component: database-init
data:
  01-extensions.sql: |
    -- Enable required extensions
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    CREATE EXTENSION IF NOT EXISTS "pg_trgm";
    CREATE EXTENSION IF NOT EXISTS "btree_gin";
    CREATE EXTENSION IF NOT EXISTS "timescaledb" CASCADE;

  02-collaboration-schema.sql: |
    -- Collaboration System Database Schema

    -- Users table
    CREATE TABLE IF NOT EXISTS users (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        email VARCHAR(255) UNIQUE NOT NULL,
        name VARCHAR(255) NOT NULL,
        avatar_url TEXT,
        created_at TIMESTAMPTZ DEFAULT NOW(),
        updated_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- Organizations table
    CREATE TABLE IF NOT EXISTS organizations (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        name VARCHAR(255) NOT NULL,
        slug VARCHAR(100) UNIQUE NOT NULL,
        settings JSONB DEFAULT '{}',
        created_at TIMESTAMPTZ DEFAULT NOW(),
        updated_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- Documents table
    CREATE TABLE IF NOT EXISTS documents (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        title VARCHAR(255) NOT NULL,
        content JSONB DEFAULT '{}',
        organization_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
        created_by UUID REFERENCES users(id) ON DELETE SET NULL,
        created_at TIMESTAMPTZ DEFAULT NOW(),
        updated_at TIMESTAMPTZ DEFAULT NOW(),
        version INTEGER DEFAULT 1
    );

    -- Document operations (CRDT operations)
    CREATE TABLE IF NOT EXISTS document_operations (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
        operation_id VARCHAR(255) NOT NULL,
        operation_type VARCHAR(50) NOT NULL,
        operation_data JSONB NOT NULL,
        actor_id UUID REFERENCES users(id) ON DELETE SET NULL,
        timestamp TIMESTAMPTZ DEFAULT NOW(),
        clock_vector JSONB DEFAULT '{}'
    );

    -- Comments table
    CREATE TABLE IF NOT EXISTS comments (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
        author_id UUID REFERENCES users(id) ON DELETE SET NULL,
        content TEXT NOT NULL,
        position JSONB,
        thread_id UUID,
        resolved BOOLEAN DEFAULT FALSE,
        created_at TIMESTAMPTZ DEFAULT NOW(),
        updated_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- Presence tracking
    CREATE TABLE IF NOT EXISTS presence (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        user_id UUID REFERENCES users(id) ON DELETE CASCADE,
        document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
        cursor_position JSONB,
        selection JSONB,
        last_seen TIMESTAMPTZ DEFAULT NOW(),
        UNIQUE(user_id, document_id)
    );

    -- Notifications
    CREATE TABLE IF NOT EXISTS notifications (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        user_id UUID REFERENCES users(id) ON DELETE CASCADE,
        type VARCHAR(100) NOT NULL,
        title VARCHAR(255) NOT NULL,
        message TEXT,
        data JSONB DEFAULT '{}',
        read BOOLEAN DEFAULT FALSE,
        created_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- Convert operations table to hypertable for time-series optimization
    SELECT create_hypertable('document_operations', 'timestamp', if_not_exists => TRUE);
    SELECT create_hypertable('notifications', 'created_at', if_not_exists => TRUE);

    -- Indexes for performance
    CREATE INDEX IF NOT EXISTS idx_documents_org_id ON documents(organization_id);
    CREATE INDEX IF NOT EXISTS idx_documents_created_by ON documents(created_by);
    CREATE INDEX IF NOT EXISTS idx_operations_document_id ON document_operations(document_id);
    CREATE INDEX IF NOT EXISTS idx_operations_timestamp ON document_operations(timestamp);
    CREATE INDEX IF NOT EXISTS idx_comments_document_id ON comments(document_id);
    CREATE INDEX IF NOT EXISTS idx_comments_author_id ON comments(author_id);
    CREATE INDEX IF NOT EXISTS idx_presence_document_id ON presence(document_id);
    CREATE INDEX IF NOT EXISTS idx_notifications_user_id ON notifications(user_id);
    CREATE INDEX IF NOT EXISTS idx_notifications_read ON notifications(read);

    -- Full-text search indexes
    CREATE INDEX IF NOT EXISTS idx_documents_content_gin ON documents USING gin(content);
    CREATE INDEX IF NOT EXISTS idx_comments_content_gin ON comments USING gin(to_tsvector('english', content));

    -- Function to update updated_at column
    CREATE OR REPLACE FUNCTION update_updated_at_column()
    RETURNS TRIGGER AS $$
    BEGIN
        NEW.updated_at = NOW();
        RETURN NEW;
    END;
    $$ language 'plpgsql';

    -- Triggers for updated_at
    CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
    CREATE TRIGGER update_organizations_updated_at BEFORE UPDATE ON organizations FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
    CREATE TRIGGER update_documents_updated_at BEFORE UPDATE ON documents FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
    CREATE TRIGGER update_comments_updated_at BEFORE UPDATE ON comments FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
