# Alertmanager configuration for Candlefish Collaboration System
global:
  # SMTP configuration for email alerts
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@candlefish.ai'
  smtp_auth_username: 'alerts@candlefish.ai'
  smtp_auth_password: '{{ env "SMTP_PASSWORD" }}'
  smtp_require_tls: true

  # Slack webhook URL
  slack_api_url: '{{ env "SLACK_WEBHOOK_URL" }}'

  # PagerDuty integration key
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# Templates for notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Routing tree
route:
  # Root route - catch all alerts
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default-receiver'

  # Child routes for different alert types
  routes:
  # Critical alerts go to PagerDuty and Slack immediately
  - match:
      severity: critical
    group_wait: 0s
    group_interval: 5m
    repeat_interval: 12h
    receiver: 'critical-alerts'
    continue: false

  # Database alerts
  - match:
      component: database
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 2h
    receiver: 'database-team'
    continue: true

  # Infrastructure alerts
  - match:
      component: infrastructure
    group_wait: 1m
    group_interval: 5m
    repeat_interval: 4h
    receiver: 'infrastructure-team'
    continue: true

  # Application alerts during business hours
  - match:
      component: collaboration
    group_wait: 1m
    group_interval: 10m
    repeat_interval: 2h
    receiver: 'application-team'
    active_time_intervals:
    - business-hours
    continue: true

  # WebSocket specific alerts
  - match:
      service: websocket
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 1h
    receiver: 'websocket-team'
    continue: true

  # Warning alerts go to Slack only
  - match:
      severity: warning
    group_wait: 5m
    group_interval: 10m
    repeat_interval: 24h
    receiver: 'warning-alerts'
    continue: false

# Time intervals
time_intervals:
- name: business-hours
  time_intervals:
  - times:
    - start_time: '09:00'
      end_time: '18:00'
    weekdays: ['monday:friday']
    location: 'America/New_York'

# Inhibition rules to reduce noise
inhibit_rules:
# Inhibit warning alerts if critical alert is firing for same service
- source_matchers:
  - severity=critical
  target_matchers:
  - severity=warning
  equal: ['service', 'instance']

# Inhibit all alerts if entire cluster is down
- source_matchers:
  - alertname=KubernetesClusterDown
  target_matchers:
  - cluster=candlefish-collaboration

# Inhibit pod alerts if node is down
- source_matchers:
  - alertname=KubernetesNodeDown
  target_matchers:
  - alertname=~"KubernetesPod.*"
  equal: ['instance']

# Receivers define how to send notifications
receivers:
# Default receiver - logs only
- name: 'default-receiver'
  webhook_configs:
  - url: 'http://alertlogger:9093/webhook'
    send_resolved: true

# Critical alerts - PagerDuty, Slack, and Email
- name: 'critical-alerts'
  pagerduty_configs:
  - routing_key: '{{ env "PAGERDUTY_INTEGRATION_KEY" }}'
    description: 'Critical Alert: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    details:
      firing: '{{ template "pagerduty.details.firing" . }}'
      resolved: '{{ template "pagerduty.details.resolved" . }}'
    images:
    - src: 'https://grafana.candlefish.ai/render/d/collaboration-overview/collaboration-overview?panelId=1&width=400&height=200'
      alt: 'Collaboration System Dashboard'
    links:
    - href: 'https://grafana.candlefish.ai/d/collaboration-overview'
      text: 'View Dashboard'
    - href: 'https://runbook.candlefish.ai'
      text: 'Runbook'

  slack_configs:
  - channel: '#alerts-critical'
    username: 'Prometheus'
    icon_emoji: ':fire:'
    title: 'CRITICAL: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: 'danger'
    actions:
    - type: button
      text: 'View Dashboard'
      url: 'https://grafana.candlefish.ai/d/collaboration-overview'
    - type: button
      text: 'Runbook'
      url: 'https://runbook.candlefish.ai/{{ range .Alerts }}{{ .Labels.alertname | toLower }}{{ end }}'
    - type: button
      text: 'Silence Alert'
      url: 'https://alertmanager.candlefish.ai/#/silences/new?filter=%7B{{ range .Alerts }}alertname%3D%22{{ .Labels.alertname }}%22{{ end }}%7D'

  email_configs:
  - to: 'oncall@candlefish.ai'
    from: 'alerts@candlefish.ai'
    subject: 'CRITICAL ALERT: {{ template "email.subject" . }}'
    html: '{{ template "email.html" . }}'

# Database team alerts
- name: 'database-team'
  slack_configs:
  - channel: '#database-alerts'
    username: 'DatabaseBot'
    icon_emoji: ':database:'
    title: 'Database Alert: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    actions:
    - type: button
      text: 'Database Dashboard'
      url: 'https://grafana.candlefish.ai/d/database-overview'

  email_configs:
  - to: 'database-team@candlefish.ai'
    from: 'alerts@candlefish.ai'
    subject: 'Database Alert: {{ template "email.subject" . }}'
    html: '{{ template "email.html" . }}'

# Infrastructure team alerts
- name: 'infrastructure-team'
  slack_configs:
  - channel: '#infrastructure-alerts'
    username: 'InfraBot'
    icon_emoji: ':gear:'
    title: 'Infrastructure Alert: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    actions:
    - type: button
      text: 'Cluster Dashboard'
      url: 'https://grafana.candlefish.ai/d/kubernetes-cluster'

  email_configs:
  - to: 'infrastructure-team@candlefish.ai'
    from: 'alerts@candlefish.ai'
    subject: 'Infrastructure Alert: {{ template "email.subject" . }}'
    html: '{{ template "email.html" . }}'

# Application team alerts
- name: 'application-team'
  slack_configs:
  - channel: '#application-alerts'
    username: 'AppBot'
    icon_emoji: ':computer:'
    title: 'Application Alert: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    actions:
    - type: button
      text: 'Application Dashboard'
      url: 'https://grafana.candlefish.ai/d/collaboration-overview'
    - type: button
      text: 'Application Logs'
      url: 'https://kibana.candlefish.ai/app/logs'

  webhook_configs:
  - url: 'https://api.candlefish.ai/webhooks/alerts'
    send_resolved: true
    http_config:
      bearer_token: '{{ env "WEBHOOK_TOKEN" }}'
    max_alerts: 10

# WebSocket team alerts
- name: 'websocket-team'
  slack_configs:
  - channel: '#websocket-alerts'
    username: 'WebSocketBot'
    icon_emoji: ':electric_plug:'
    title: 'WebSocket Alert: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    fields:
    - title: 'Active Connections'
      value: '{{ range .Alerts }}{{ if eq .Labels.alertname "WebSocketHighConnectionCount" }}{{ .Annotations.description }}{{ end }}{{ end }}'
      short: true
    - title: 'Connection Drops'
      value: '{{ range .Alerts }}{{ if eq .Labels.alertname "WebSocketHighConnectionDrops" }}{{ .Annotations.description }}{{ end }}{{ end }}'
      short: true

# Warning alerts - Slack only
- name: 'warning-alerts'
  slack_configs:
  - channel: '#alerts-warning'
    username: 'PrometheusBot'
    icon_emoji: ':warning:'
    title: 'Warning: {{ template "slack.title" . }}'
    text: '{{ template "slack.text" . }}'
    color: 'warning'
    actions:
    - type: button
      text: 'View Details'
      url: 'https://grafana.candlefish.ai/d/collaboration-overview'

# Message templates
templates:
- '/etc/alertmanager/templates/default.tmpl'
- '/etc/alertmanager/templates/slack.tmpl'
- '/etc/alertmanager/templates/email.tmpl'
- '/etc/alertmanager/templates/pagerduty.tmpl'
